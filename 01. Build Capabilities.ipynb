{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "path_in = 'data'\n",
    "path_out = 'data/temp02'\n",
    "today = pd.Timestamp.today()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load files\n",
    "CAPABILITIES = pd.read_pickle('data/temp01/CAPABILITIES.pkl')\n",
    "WO_HEADER = pd.read_pickle('data/temp01/WO_HEADER.pkl')\n",
    "VIP_LRU =  pd.read_pickle('data/temp01/VIP_LRU.pkl')\n",
    "LOST_BIZ =  pd.read_pickle('data/temp01/LOST_BIZ.pkl')\n",
    "PARTS_MASTER = pd.read_pickle('data/temp01/PARTS_MASTER.pkl')\n",
    "\n",
    "WO_HEADER['COMMENT'] = np.NaN\n",
    "\n",
    "#flag PN that are not in Parts Master (those wont generate nothing)\n",
    "PARTS_MASTER.drop(columns = ['DESCRIPTION','PNM','CLASS','LIST_PRICE','PRICEDATE','CODE','MFG'],inplace = True)\n",
    "PARTS_MASTER.drop_duplicates(subset = 'PN', inplace = True, keep = 'last')\n",
    "WO_HEADER = pd.merge(WO_HEADER, PARTS_MASTER,  how='left', left_on='PN', right_on = 'PN')\n",
    "\n",
    "\n",
    "#merge WO and capa\n",
    "WO_HEADER = pd.merge(WO_HEADER, CAPABILITIES,  how='left', left_on=['PN','GEO_CODE'], right_on = ['PN','GEO_CODE'] )\n",
    "\n",
    "#find top active shop for a PN\n",
    "LIST_LRUS = pd.DataFrame(index = WO_HEADER['PN'].unique(), columns=['TOP_GEO_CODE'])\n",
    "VOLUME_PER_GEO_CODE = WO_HEADER[WO_HEADER['IS_ACTIVE'] == 1].pivot_table(\n",
    "    aggfunc=len, values='WONO', columns=['PN'], index='GEO_CODE')\n",
    "\n",
    "for column in VOLUME_PER_GEO_CODE: #MAYBE CHANGE THIS FOR A PIVOT TABLE FOR FASTER PROCESSING\n",
    "    LIST_LRUS['TOP_GEO_CODE'][column]= VOLUME_PER_GEO_CODE[column].idxmax() #assign top shop\n",
    "    VOLUME_PER_GEO_CODE[column][VOLUME_PER_GEO_CODE[column].idxmax()] = np.NaN #change top shop value to 0 to then test next top shop\n",
    "\n",
    "#bring number of open capa\n",
    "LIST_LRUS = pd.merge(LIST_LRUS,\n",
    "                     CAPABILITIES.pivot_table(aggfunc=sum,index='PN', values='IS_ACTIVE'),\n",
    "                     left_index = True, right_index = True, how = 'left')\n",
    "\n",
    "LIST_LRUS.rename(columns = {'IS_ACTIVE':'NB_ACTIVE_CAPS'}, inplace = True)\n",
    "\n",
    "#bring top shop active shop\n",
    "WO_HEADER = pd.merge(WO_HEADER, LIST_LRUS, right_index = True , how = 'left',left_on = 'PN')\n",
    "\n",
    "#-------determine the best geo_code\n",
    "WO_HEADER['ADJ_GEO_CODE'] = np.NaN\n",
    "#--if active then keep\n",
    "WO_HEADER.loc[WO_HEADER.IS_ACTIVE == 1, 'ADJ_GEO_CODE'] = WO_HEADER['GEO_CODE'] \n",
    "#--if not active and only one cap is open then bring it\n",
    "#build table showing PN with only 1 active cap, and show that cap back in WO_HEADER\n",
    "LIST_LRUS_ONE_CAP = pd.DataFrame(\n",
    "    index = WO_HEADER[(WO_HEADER['IS_ACTIVE'] != 1) & (WO_HEADER['NB_ACTIVE_CAPS'] == 1)]['PN'].unique())\n",
    "LIST_LRUS_ONE_CAP = pd.merge(\n",
    "    LIST_LRUS_ONE_CAP,CAPABILITIES[CAPABILITIES['IS_ACTIVE']==1],how='left',left_index = True, right_on = 'PN')\n",
    "LIST_LRUS_ONE_CAP.rename(inplace = True, columns ={'GEO_CODE':'ONLY_ACTIVE_GEO_CODE'})\n",
    "LIST_LRUS_ONE_CAP.drop(columns=['IS_ACTIVE'], inplace = True)\n",
    "WO_HEADER = pd.merge(WO_HEADER,LIST_LRUS_ONE_CAP,left_on='PN',right_on='PN', how = 'left')\n",
    "WO_HEADER.loc[(WO_HEADER.IS_ACTIVE != 1) & (WO_HEADER.NB_ACTIVE_CAPS == 1),\n",
    "              'ADJ_GEO_CODE'] = WO_HEADER['ONLY_ACTIVE_GEO_CODE']\n",
    "#--if not active but multiple caps open then change to top geo code\n",
    "WO_HEADER.loc[(WO_HEADER.IS_ACTIVE != 1) & (WO_HEADER.NB_ACTIVE_CAPS != 1), 'ADJ_GEO_CODE'] = WO_HEADER['TOP_GEO_CODE']\n",
    "\n",
    "#remove unwanted rows (dont really delete rows, just add a comment)\n",
    "\n",
    "WO_HEADER['COMMENT'] = np.where(WO_HEADER['ADJ_GEO_CODE'] == 'MIA GSTE', 'TO REMOVE: GEO_CODE IS GSTE', WO_HEADER['COMMENT'])\n",
    "WO_HEADER['COMMENT'] = np.where(WO_HEADER['ADJ_GEO_CODE'].isnull(), 'TO REMOVE: NO ACTIVE CAPABILITY', WO_HEADER['COMMENT'])\n",
    "\n",
    "\n",
    "#add GEO_CODE_UPPER columns\n",
    "UPPER_GEO_CODE = DataFrame(columns=['GEO_CODE','UPPER_GEO_CODE'],\n",
    "                           data =[['MIA MRO','BIC'],['PHX','BIC'],['SDF','BIC'],['DOR','ARO'],['MED MRO','ARO']])\n",
    "WO_HEADER = WO_HEADER.merge(UPPER_GEO_CODE, left_on ='ADJ_GEO_CODE', right_on = 'GEO_CODE',how='left')\n",
    "\n",
    "#drop unused columns\n",
    "WO_HEADER = WO_HEADER.drop(columns=['GEO_CODE_x','IS_ACTIVE','TOP_GEO_CODE',\n",
    "                                    'NB_ACTIVE_CAPS','ONLY_ACTIVE_GEO_CODE','GEO_CODE_y'])\n",
    "\n",
    "#show VIPs\n",
    "WO_HEADER = WO_HEADER .merge(VIP_LRU,left_on='PN',right_on='PN',how='left')\n",
    "WO_HEADER.rename(columns={'GEO_CODE_UPPER':'VIP_STATUS','Date_entered':'VIP_STATUS_DATE'},inplace=True)\n",
    "\n",
    "#remove Lost Biz (remove all occurences after termination date - TODO add warning to users to review aging items)\n",
    "WO_HEADER = WO_HEADER.merge(LOST_BIZ,on=['PN','COMPANY_CODE','UPPER_GEO_CODE'],how='left')\n",
    "LOST_BIZ.drop_duplicates(subset=['PN','COMPANY_CODE','UPPER_GEO_CODE'],inplace = True)\n",
    "WO_HEADER.drop(columns=['Date entered'],inplace= True)\n",
    "WO_HEADER['COMMENT'] = np.where(~WO_HEADER['Termination date'].isnull(), 'TO REMOVE: LOST BUSINESS', WO_HEADER['COMMENT'])\n",
    "WO_HEADER['COMMENT'] = np.where(WO_HEADER['STC'].isnull(), 'TO WARN: LRUs PN NOT IN MASTER', WO_HEADER['COMMENT'])\n",
    "\n",
    "#save as pickle\n",
    "WO_HEADER.to_pickle('data/temp02/WO_HEADER.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
